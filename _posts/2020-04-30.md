---
title: "강화학습"
type: post
permalink: /study/ai/DL
category: 
    - STUDY
        - etc
tag:
    - AI
toc: ture
siderbar_main: true
---
본 내용은 [인공지능의 이해](https://www.edwith.org/knusw-ai)의 내용을 참조하여 작성하였습니다.  

# 딥러닝
## 신경망
형식 뉴런을 여러개 이어서 수학적 신경회로를 구성 돼 있으며,  
인간 두뇌에 대한 계산적 모델을 통해 인공지능을 구현하려는 분야

### 활성화 함수
형식 뉴런에서 받은 입력값을 출력할 때 일정한 기준에 따라 출력값을 변화시키는 비선형 함수

### 퍼셉트론
학습가능한 신경망 모델로,  
세 가지로 구성된다.  
- 선형 신경의 기울기인 가중치
- 선형 신경의 절편인 바이어스
- 입력값에 따라 0 또는 1의 값을 출력해주는 활성화 함수

### 다층 퍼셉트론
여러 개의 퍼셉트론을 층 구조로 구성한 신경망 모델로,  
세 가지로 구성된다.  
- 입력계층, 은닉계층, 출력 계층으로 구성

## 딥러닝
신경망의 발전 형태로,  
다층 신경망을 이용하여, 입력 데이터의 특징을 추출해 모델을 만드는 기계학습 기법이며,  
내부 작동 원리를 알지 못하는 블랙박스 모델이다.

## 기울기 소멸 문제
은닉층이 많은 다층 퍼셉트론이 존재할 때 입력층에 근접한 층들의 가중치가 잘 학습이 되지 않는 현상

### 해결 방법
미분을 실시하여도 값이 급속하게 줄지 않게 ReLU 함수를 사용한다.  
ReLU 함수의 편미분 값은  
입력이 0 미만이면 0,  
입력이 0 이상이면 1  
이므로 다른 함수처럼 기울기 소멸 문제가 발생하지 않는다.

## 가중치 초기값
가중치는 신경망 성능에 큰 영향을 주는 요소로,  
초기 값은 0에 가까운 무작위 값을 사용하게 된다.

### 개선된 가중치 초기화 방법
- 균등분포에서 무작위로 선택
- 각 노드의 입력 노으 개수와 출력 노드의 개수를 사용하는 방법
- 제어비어 초기화
- 허 초기화

## 과적합
모델이 학습 데이터에 과하게 적응한 경우로,  
학습 되지 않은 데이터에 대해선 성능이 저하 된다.  

### 과적합 문제 완화 기법
- 규제화
- 드롭아웃
- 배치 정규화

### 규제화
오차 함수를 오차항과 모델 복잡도 항으로 정의하여  
모델이 복잡해 지면 모델 복잡도를 벌점으로 추가한다.  

### 드롭아웃
일정 확률로 노드들을 무작위로 선택하여,  
선택된 노드의 앞 뒤로 연결된 가중치 연결선을 없는 것으로 취급하여 학습
이때, 추론할 때는 사용하지 않고 학습시에만 사용한다.

### 배치 정규화
**내부 공변량 이동 문제**  
이전 층들의 학습에 의해 이들 층의 가중치가 바뀌게 되면,  
현재 층에 전달되는 데이터의 분포가 현재 층이 학습했던 시점의 분포와 차이가 발생한다.  
즉, 학습 속도가 저하된다.

데이터의 평균값과 표준편차를 최소화 하는 기법