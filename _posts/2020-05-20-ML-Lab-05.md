---
title: "Logistic(Regression) Classification TensorFlow 구현"
type: post
permalink: /study/ai/ML_Lab_05
category: 
    - STUDY
        - etc
tag:
    - AI
use_math: true
toc: ture
siderbar_main: true
---
본 글은 [모두를 위한 머신러닝/딥러닝 강의](https://hunkim.github.io/ml/)를 참고하여 작성하였습니다.  
소스 코드는 [DeepLearningZeroToAll](https://github.com/hunkim/DeepLearningZeroToAll)를 참고 하여 작성하였습니다.

# ML lab 05: TensorFlow로 Logistic Classification의 구현하기
지난 시간에 다뤘던 로지스틱 회귀의 가정과 비용함수에 대해 다뤄보기로 하겠습니다.  

아래 식은 가정과 비용함수 입니다.  

$$ H(X) = \frac{1}{1+e^{-W^TX} } $$ 

$$ 
\text{cost}(W) = 
-\frac{1}{m}\sum ylog(H(x)) + (1-y)log(1-H(x)) $$

$$W := W - \alpha \frac{\partial}{\partial{W} } $$



```python
import tensorflow as tf
```

## Training Data


```python
x_data = [[1, 2],
          [2, 3],
          [3, 1],
          [4, 3],
          [5, 3],
          [6, 2]]
y_data = [[0],
          [0],
          [0],
          [1],
          [1],
          [1]]
```


```python
tf.model = tf.keras.Sequential()
tf.model.add(tf.keras.layers.Dense(units = 1, input_dim = 2))
```


```python
tf.model.add(tf.keras.layers.Activation('sigmoid'))
```

$ H(X) $의 부분이 `sigmoid`의 형태이므로,  
활성화 함수 부분에 `sigmoid`를 넣어준다. 


```python
tf.model.compile(loss = 'binary_crossentropy', optimizer = tf.keras.optimizers.SGD(lr=0.01), metrics = ['accuracy'])
tf.model.summary()
```

    Model: "sequential"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    dense (Dense)                (None, 1)                 3         
    _________________________________________________________________
    activation (Activation)      (None, 1)                 0         
    =================================================================
    Total params: 3
    Trainable params: 3
    Non-trainable params: 0
    _________________________________________________________________
    


```python
history = tf.model.fit(x_data, y_data, epochs = 5000)
```

```python
print("Accuracy: ", history.history['accuracy'][-1])
```

    Accuracy:  1.0
    
