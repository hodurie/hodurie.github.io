---
title: "여러개의 입력(feature)의 Linear Regression"
type: post
permalink: /study/ai/ML_Lec_04
category: 
    - STUDY
        - etc
tag:
    - AI
use_math: true
toc: ture
siderbar_main: true
---
본 글은 [모두를 위한 머신러닝/딥러닝 강의](https://hunkim.github.io/ml/)를 참고하여 작성하였습니다.  
소스 코드는 [DeepLearningZeroToAll](https://github.com/hunkim/DeepLearningZeroToAll)를 참고 하여 작성하였습니다.

# ML lec 04 - multi-variable linear regression
지난 시간에는 변수가 하나인 선형회귀식에 대해 알아봤습니다.  
오늘은 변수의 개수가 두 개 이상인 선형회귀식에 대해 알아보겠습니다.  

## Multi-Variable Linear Regression
위에서 언급했다시피 식을 이용해 $y$ 값을 예측할 때,  
하나의 값이 아닌 여러 개의 값을 사용합니다.  

여러 개의 값을 사용한다면,  
이전에 설정했던 가설과 비용함수도 달라질까요?  
질문의 답은 그렇다 입니다.  

그렇다면, 변수의 개수에 따라 어떻게 변화했는지 알아보도록 하겠습니다.  
먼저, $x$의 개수가 세 개라고 정한 후 진행하도록 하겠습니다.  

기존 단순 선형회귀의 경우  

$$ H(x) = Wx + b $$

와 같이 표현했습니다.  
하지만, 다중 선형회귀(다변수 선형회귀)는 $x$의 값이 많으므로,  
$x$들에 대한 $w$를 따로따로 표현해 줘야 합니다.  

$$ H(x_1, x_2, x_3) = w_1x_1 + w_2x_2 + w_3x_3 + b  $$

비용함수의 경우에도 달라진 $x$에 대해서 다르게 표현해 줘야 합니다.  

$$ \mathbf{cost}(W, b) = { {1} \over {m} }\sum_{i = 1}^m(H(x_{1i}, x_{2i}, x_{3i}) - y_i)^2 $$

만약, $x$의 값이 세 개가 아닌 열 개, 백 개와 같이 많은 값을 갖게 된다면,  
우리는 이를 표현하기가 매우 불편합니다.  

이를 간단하게 표현할 수 있게 해주는 것이 바로  
**Matrix** 입니다.  

**Matrix**를 이용하면, 우리는 위의 식을 간단하게 표현할 수 있습니다.  
가설의 식들은 $x$와 $w$의 곱으로 이루어져 있습니다.  
이를 따로 분리해서 생각해보면  
$x$ 벡터와 $w$벡터의 곱으로서 나타낼 수 있습니다.  

두 개의 식을 곱해서 나타낸 **Matrix**로 식을 표현하면  

$$ H(x) = XW $$

와 같이 표현 할 수 있습니다.  

이를 일반화 하면, 여러 $x$의 값을 가진 행렬과  
$w$ 벡터의 곱으로 이를 표현 할 수 있습니다.  

하지만, 여기서 주의할 점이 하나 있습니다.  
바로 행렬들의 차원을 고려해 줘야 된다는 점입니다.  
행렬의 곱은 행 곱하기 열을 통해 나타내며,  
두 개의 행렬 중 앞 행렬의 열과 뒤 행렬의 행의 차원이 같아야 합니다.  

예를들어,  
$A$는 3행 4열 행열,    
$B$는 4행 1열 행렬(벡터)  
일 때, $A \dot B$는 가능하지만, $B \dot A$는 불가능 합니다.  

또한, 곱이후에 만들어 지는 행렬은 앞 행렬의 행의 뒤 행렬의 열의 차원으로 만들어집니다.  
위의 예를 갖고 말하면,  
$A \dot B$는 3행 1열의 행렬이 만들어 집니다.